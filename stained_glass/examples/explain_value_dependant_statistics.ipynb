{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stained_glass.idealized as idealized\n",
    "import stained_glass.stats as stats\n",
    "import stained_glass.sample as sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sightlines\n",
    "n = 10000\n",
    "r_clump = 6.\n",
    "sidelength = 600.\n",
    "r_bins = np.arange( 0., sidelength/2, 10.)\n",
    "annuli = np.array([ 0., 90., 120., 150., 180., 210., 300., ])\n",
    "levels = np.array([ 1., 2., 3., 4., 5., 6. ])\n",
    "edges_log = np.logspace( -1., np.log10( sidelength) , 16 )\n",
    "edges = np.linspace( 0., sidelength, 16 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = edges[:-1] + 0.5 * ( edges[1] - edges[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_log = 10.**( np.log10( edges_log[:-1] ) + 0.5 * ( np.log10( edges_log[1] ) - np.log10( edges_log[0] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_bin = round( n / (edges_log.size - 1 ) / 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DEBUG\n",
    "xs_log = xs\n",
    "edges_log = edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup idealized projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips = []\n",
    "all_length_scales = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radial distribution\n",
    "ip = idealized.IdealizedProjection(sidelength)\n",
    "ip.add_ellipse(\n",
    "    c = (0., 0.),\n",
    "    a = 90.,\n",
    "    value = levels[5],\n",
    ")\n",
    "length_scales = {}\n",
    "length_scales['core'] = 90.\n",
    "\n",
    "structs, values = copy.copy( ip.structs ), copy.copy( ip.struct_values )\n",
    "for i, (struct, value) in enumerate( zip( *[ structs, values ] ) ):\n",
    "    ip.add_concentric_structures(\n",
    "        struct,\n",
    "        value = levels[5],\n",
    "        n_concentric = 4,\n",
    "        dr = 30.,\n",
    "    )\n",
    "\n",
    "ips.append( ip )\n",
    "all_length_scales.append( length_scales )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radial distribution and satellite\n",
    "ip = idealized.IdealizedProjection(sidelength)\n",
    "ip.add_ellipse(\n",
    "    c = (0., 0.),\n",
    "    a = 90.,\n",
    "    value = levels[5],\n",
    ")\n",
    "length_scales = {}\n",
    "length_scales['core'] = 90.\n",
    "ip.add_ellipse(\n",
    "    c = (180., 180.),\n",
    "    a = 40.,\n",
    "    value = levels[4],\n",
    ")\n",
    "length_scales['satellite'] = 40.\n",
    "\n",
    "structs, values = copy.copy( ip.structs ), copy.copy( ip.struct_values )\n",
    "for i, (struct, value) in enumerate( zip( *[ structs, values ] ) ):\n",
    "    ip.add_concentric_structures(\n",
    "        struct,\n",
    "        value = levels[5],\n",
    "        n_concentric = 4,\n",
    "        dr = 30.,\n",
    "    )\n",
    "\n",
    "ips.append( ip )\n",
    "all_length_scales.append( length_scales )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clumps\n",
    "ip = idealized.IdealizedProjection(sidelength)\n",
    "ip.add_clumps(\n",
    "    r_clump = r_clump,\n",
    "    c = (0., 0.),\n",
    "    r_area = 150.,\n",
    "    fcov = 0.5,\n",
    "    value = levels[5],\n",
    ")\n",
    "length_scales = {}\n",
    "length_scales['core'] = 150.\n",
    "length_scales['clump'] = r_clump\n",
    "\n",
    "structs, values = copy.copy( ip.structs ), copy.copy( ip.struct_values )\n",
    "for i, (struct, value) in enumerate( zip( *[ structs, values ] ) ):\n",
    "    ip.add_concentric_structures(\n",
    "        struct,\n",
    "        value = levels[5],\n",
    "        n_concentric = 4,\n",
    "        dr = 10.,\n",
    "    )\n",
    "\n",
    "ips.append( ip )\n",
    "all_length_scales.append( length_scales )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filament\n",
    "ip = idealized.IdealizedProjection(sidelength)\n",
    "ip.add_curve(\n",
    "    v1 = (0., 0.),\n",
    "    v2 = (-300., 60.),\n",
    "    theta_a = 20.,\n",
    "    theta_b = 60.,\n",
    "    value = levels[5],\n",
    ")\n",
    "length_scales = {}\n",
    "length_scales['long'] = np.sqrt( 300.**2. + 60.**2. )\n",
    "\n",
    "structs, values = copy.copy( ip.structs ), copy.copy( ip.struct_values )\n",
    "for i, (struct, value) in enumerate( zip( *[ structs, values ] ) ):\n",
    "    ip.add_concentric_structures(\n",
    "        struct,\n",
    "        value = levels[5],\n",
    "        n_concentric = 4,\n",
    "        dr = 30.,\n",
    "    )\n",
    "\n",
    "ips.append( ip )\n",
    "all_length_scales.append( length_scales )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the above\n",
    "ip = idealized.IdealizedProjection(sidelength)\n",
    "ip.add_ellipse(\n",
    "    c = (0., 0.),\n",
    "    a = 90.,\n",
    "    value = levels[5],\n",
    ")\n",
    "length_scales = {}\n",
    "length_scales['core'] = 90.\n",
    "ip.add_ellipse(\n",
    "    c = (180., 180.),\n",
    "    a = 60.,\n",
    "    value = levels[4],\n",
    ")\n",
    "length_scales['satellite'] = 60.\n",
    "ip.add_clumps(\n",
    "    r_clump = r_clump,\n",
    "    c = (0., 0.),\n",
    "    r_area = 150.,\n",
    "    fcov = 0.5,\n",
    "    value = levels[5],\n",
    ")\n",
    "length_scales['clump'] = r_clump\n",
    "ip.add_curve(\n",
    "    v1 = (0., 0.),\n",
    "    v2 = (-300., 60.),\n",
    "    theta_a = 20.,\n",
    "    theta_b = 60.,\n",
    "    value = levels[5],\n",
    ")\n",
    "length_scales['filament'] = np.sqrt( 300.**2. + 60.**2. )\n",
    "\n",
    "structs, values = copy.copy( ip.structs ), copy.copy( ip.struct_values )\n",
    "for i, (struct, value) in enumerate( zip( *[ structs, values ] ) ):\n",
    "    ip.add_concentric_structures(\n",
    "        struct,\n",
    "        value = levels[5],\n",
    "        n_concentric = 4,\n",
    "        dr = 30.,\n",
    "    )\n",
    "\n",
    "ips.append( ip )\n",
    "all_length_scales.append( length_scales )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add backgrounds\n",
    "[ ip.add_background( levels[0] ) for ip in ips ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Projections\n",
    "[ ip.generate_idealized_projection() for ip in ips ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tpcfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate weighted TPCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcfs = []\n",
    "means = []\n",
    "for i, ip in enumerate( ips ):\n",
    "    \n",
    "    # Get data\n",
    "    ip.generate_sightlines( n )\n",
    "    ws = ip.evaluate_sightlines()\n",
    "    coords = np.array([ ip.sl_xs, ip.sl_ys ]).transpose()\n",
    "    \n",
    "    tpcf, edges = stats.weighted_tpcf(\n",
    "        coords,\n",
    "        ws,\n",
    "        edges_log,\n",
    "    )\n",
    "    \n",
    "    tpcfs.append( tpcf )\n",
    "    \n",
    "    # Store the fiducially-sampled mean for more consistent normalization later\n",
    "    means.append( np.nanmean( ws ) )\n",
    "    \n",
    "all_tpcfs[( 'W', )] = tpcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate radially-normalized, weighted TPCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcfs = []\n",
    "for i, ip in enumerate( ips ):\n",
    "    \n",
    "    # Get data\n",
    "    ip.generate_sightlines( n )\n",
    "    ws = ip.evaluate_sightlines()\n",
    "    coords = np.array([ ip.sl_xs, ip.sl_ys ]).transpose()\n",
    "    \n",
    "    tpcf, edges = stats.radial_weighted_tpcf(\n",
    "        coords,\n",
    "        ws,\n",
    "        edges_log,\n",
    "        r_bins = r_bins,\n",
    "    )\n",
    "    \n",
    "    tpcfs.append( tpcf )\n",
    "    \n",
    "all_tpcfs[( 'RN', 'W', )] = tpcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Paired Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_edges = np.array([ ip.ip_values.min(), ip.ip_values.max() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sampler = sample.PairSampler( ip.sidelength, edges_log, v_edges )\n",
    "dr_coords1, dr_coords2 = pair_sampler.generate_pair_sampling_coords(\n",
    "    n_per_bin = n_per_bin,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_coords = np.concatenate([ np.concatenate( dr_coords1 ), np.concatenate( dr_coords2 ) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the normalizations using the means from non-paired sampling\n",
    "means = np.array( means )\n",
    "normalizations = means ** -2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate radially-normalized, pair-sampled, weighted TPCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcfs = []\n",
    "for i, ip in enumerate( ips ):\n",
    "    \n",
    "    # Get data\n",
    "    ip.set_sightlines( pair_coords )\n",
    "    ws = ip.evaluate_sightlines()\n",
    "    \n",
    "    tpcf, edges = stats.radial_weighted_tpcf(\n",
    "        pair_coords,\n",
    "        ws,\n",
    "        edges_log,\n",
    "        r_bins = r_bins,\n",
    "#         normalization = normalizations[i],\n",
    "    )\n",
    "    \n",
    "    tpcfs.append( tpcf )\n",
    "    \n",
    "all_tpcfs[( 'RN', 'PS', 'W', )] = tpcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate annuli-binned, pair-sampled, weighted TPCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcfs = []\n",
    "annuli_medians = []\n",
    "for i, ip in enumerate( ips ):\n",
    "    \n",
    "    # Get data\n",
    "    ip.set_sightlines( pair_coords )\n",
    "    ws = ip.evaluate_sightlines()\n",
    "    \n",
    "    tpcf, edges = stats.annuli_weighted_tpcf(\n",
    "        pair_coords,\n",
    "        ws,\n",
    "        edges_log,\n",
    "        r_bins = annuli,\n",
    "#         normalization = normalizations[i],\n",
    "    )\n",
    "    \n",
    "    tpcfs.append( tpcf )\n",
    "    \n",
    "    # Annuli medians for later use\n",
    "    medians = []\n",
    "    r = np.sqrt( ( pair_coords**2. ).sum( axis=1 ) )\n",
    "    for i in range( len( annuli ) - 1 ):\n",
    "        in_annuli = ( annuli[i] < r ) & ( r < annuli[i+1] ) \n",
    "        medians.append( np.nanmedian( ws[in_annuli] ) )\n",
    "    annuli_medians.append( medians )\n",
    "    \n",
    "all_tpcfs[( 'A', 'PS', 'W', )] = tpcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pair-sampled, weighted TPCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcfs = []\n",
    "for i, ip in enumerate( ips ):\n",
    "    \n",
    "    # Get data\n",
    "    ip.set_sightlines( pair_coords )\n",
    "    ws = ip.evaluate_sightlines()\n",
    "    \n",
    "    tpcf, edges = stats.weighted_tpcf(\n",
    "        pair_coords,\n",
    "        ws,\n",
    "        edges_log,\n",
    "        normalization = normalizations[i],\n",
    "    )\n",
    "    \n",
    "    tpcfs.append( tpcf )\n",
    "    \n",
    "all_tpcfs[( 'PS', 'W', )] = tpcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pair-sampled TPCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tpcfs = []\n",
    "for ip in ips:\n",
    "    ip.evaluate_pair_sampled_tpcf(\n",
    "        edges,\n",
    "        0.5,\n",
    "        4.5,\n",
    "        estimator = 'simple',\n",
    "        n_per_bin = n_per_bin,\n",
    "    )\n",
    "    tpcfs.append( tpcf )\n",
    "    \n",
    "all_tpcfs[( 'PS', )] = tpcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Different Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tpcfs = verdict.Dict( all_tpcfs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_min = all_tpcfs.apply( np.array ).apply( np.nanmin ).keymin()[1]\n",
    "global_max = all_tpcfs.apply( np.array ).apply( np.nanmax ).keymax()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = len( ips )\n",
    "nrows = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = palettable.cartocolors.qualitative.Safe_10.mpl_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_or_not( label, do_label ):\n",
    "    \n",
    "    if do_label:\n",
    "        return label\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(3*ncols, 3*nrows), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "gs = gridspec.GridSpec( nrows, ncols )\n",
    "gs.update( wspace=0.0001, hspace=0.0001 )\n",
    "\n",
    "for i, ip in enumerate( ips ):\n",
    "    \n",
    "    # Plot the idealized image\n",
    "    ax = plt.subplot( gs[0,i], )\n",
    "    ip.plot_idealized_projection(\n",
    "        ax,\n",
    "    )\n",
    "    \n",
    "    # Fiducial\n",
    "    ax = plt.subplot( gs[2,i], )\n",
    "        \n",
    "    # Plot Fiducial\n",
    "    tpcf = all_tpcfs[( 'RN', 'PS', 'W', )][i]\n",
    "    ax.plot(\n",
    "        xs_log,\n",
    "        tpcf,\n",
    "        linewidth = 3,\n",
    "        color = 'k',\n",
    "        label = label_or_not( 'fiducial', ax.is_first_col() )\n",
    "    )\n",
    "    \n",
    "    # Plot w/o pair-sampling\n",
    "    tpcf = all_tpcfs[( 'RN', 'W', )][i]\n",
    "    ax.plot(\n",
    "        xs_log,\n",
    "        tpcf,\n",
    "        linewidth = 3,\n",
    "        color = 'k',\n",
    "        label = label_or_not( 'no pair sampling', ax.is_first_col() ),\n",
    "        linestyle = '--',\n",
    "    )\n",
    "    \n",
    "#     ax.set_ylim( -0.01, 5.0 )\n",
    "    ax.set_ylim( -0.05, 0.55 )\n",
    "    \n",
    "    # Radial normalization comparison\n",
    "    ax = plt.subplot( gs[1,i], )\n",
    "    \n",
    "    # Plot Fiducial\n",
    "    tpcf = all_tpcfs[( 'RN', 'PS', 'W', )][i]\n",
    "    ax.plot(\n",
    "        xs_log,\n",
    "        tpcf,\n",
    "        linewidth = 3,\n",
    "        color = 'k',\n",
    "    )\n",
    "    \n",
    "    # Plot w/o radial normalization\n",
    "    tpcf = all_tpcfs[( 'PS', 'W', )][i]\n",
    "    ax.plot(\n",
    "        xs_log,\n",
    "        tpcf,\n",
    "        linewidth = 3,\n",
    "        color = colors[1],\n",
    "        label = label_or_not( 'no radial normalization', ax.is_first_col() ),\n",
    "    )\n",
    "    \n",
    "    # Plot only weighted\n",
    "    tpcf = all_tpcfs[( 'W', )][i]\n",
    "    ax.plot(\n",
    "        xs_log,\n",
    "        tpcf,\n",
    "        linewidth = 3,\n",
    "        color = colors[1],\n",
    "        linestyle = '--',\n",
    "        label = label_or_not( 'only weighting', ax.is_first_col() ),\n",
    "    )\n",
    "    \n",
    "    ax.set_ylim( global_min, global_max )\n",
    "    \n",
    "    # Annuli\n",
    "    ax = plt.subplot( gs[3,i], )\n",
    " \n",
    "    # Plot w/o radial normalization\n",
    "    tpcfs = all_tpcfs[( 'A', 'PS', 'W', )][i]\n",
    "    values = levels[::-1]\n",
    "    for k, tpcf in enumerate( tpcfs ):\n",
    "        ax.plot(\n",
    "            xs_log,\n",
    "            tpcf,\n",
    "            linewidth = 3,\n",
    "            color = ip.color_chooser( values[k] ),\n",
    "        )\n",
    "    ax.set_ylim( 0., 3. )\n",
    "        \n",
    "# Go back through and fix up axes\n",
    "for i in range( ncols ):\n",
    "    for j in range( nrows ):\n",
    "        \n",
    "        ax = plt.subplot( gs[j,i], )\n",
    "        \n",
    "        # Projection Plot options\n",
    "        if j < 1:\n",
    "            \n",
    "            ax.set_aspect( 'equal' )\n",
    "            ax.tick_params( labelleft=False, labelbottom=False, left=False, bottom=False)\n",
    "            \n",
    "        # Statistics options\n",
    "        if j >= 1:\n",
    "            \n",
    "\n",
    "            # Length scales\n",
    "            for key, item in all_length_scales[i].items():\n",
    "                ax.axvline(\n",
    "                    item,\n",
    "                    linewidth = 1.,\n",
    "                    color = '.3',\n",
    "                    linestyle = '--',\n",
    "                )\n",
    "            \n",
    "            # Remove tick labels\n",
    "            if not ax.is_first_col():\n",
    "                ax.tick_params( labelleft=False, left=False, )\n",
    "            if not ax.is_last_row():\n",
    "                ax.tick_params( labelbottom=False, bottom=False, )\n",
    "            ax.tick_params( which='minor', bottom=True, )\n",
    "            \n",
    "            # Limits for statistics\n",
    "            ax.set_xlim( xs_log[0], xs_log[-1] )\n",
    "#             ax.set_ylim( global_min, global_max )\n",
    "            \n",
    "            ax.set_xscale( 'log' )\n",
    "#             ax.set_yscale( 'log' )\n",
    "#             ax.set_yscale( 'symlog' )\n",
    "            \n",
    "            if ax.is_last_row():\n",
    "                ax.set_xlabel( r'$\\Delta x$', fontsize=22 )\n",
    "            if ax.is_first_col():\n",
    "                ax.set_ylabel( r'$M(\\Delta x)$', fontsize=22 )\n",
    "          \n",
    "#             # Legend\n",
    "#             if ax.is_first_col():\n",
    "#                 ax.legend(\n",
    "#                     bbox_to_anchor = (0.0, 2.02, 5., 0.5 ),\n",
    "#                     loc = 'lower left',\n",
    "#                     ncol = 4,\n",
    "#                     mode = \"expand\",\n",
    "#                     borderaxespad = 0.,\n",
    "#                     prop = {'size': 16},\n",
    "#                 )\n",
    "\n",
    "lgd = fig.legend(\n",
    "    bbox_to_anchor = (0.1, 0.87, 0.7, 1.0 ),\n",
    "    loc = 'lower left',\n",
    "    ncol = 4,\n",
    "    mode = \"expand\",\n",
    "    borderaxespad = 0.,\n",
    "    prop = {'size': 16},\n",
    ")\n",
    "\n",
    "fig.savefig('./weighted_correlations.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiple-per-halo statistics to consider are\n",
    "[Radially-normalized], [pair-sampled], [weighted] TPCF [per cut on N].\n",
    "\n",
    "~The default should be with everything except for the N bins turned on.~\n",
    "\n",
    "~One row will show the effect of turning on/off pair sampling (should be log-spaced).~\n",
    "\n",
    "One row will show the effect of turning on/off radial bins.\n",
    "\n",
    "~One row will show the effect of turning on/off radial-normalization.~\n",
    "\n",
    "One row will show the effect of turning off weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issue: Depending on how the radial subtraction is done the normalization is different from the normalization when different annuli are done separately.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issue: If radial trends are accounted for by division there shouldn't be values below one, but there are values below one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_bin"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$M(\\Delta x) = ( \\sum_{all pairs with \\Delta x} w_i w_j ) / ( \\bar{ w }^2 DD(\\Delta x ) )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
