{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.interpolate\n",
    "import scipy.optimize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import palettable\n",
    "import descartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stained_glass.generate as generate\n",
    "import stained_glass.idealized as idealized\n",
    "import stained_glass.stats as stats\n",
    "import stained_glass.sample as sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sightlines\n",
    "n = 10000\n",
    "sidelength = 600.\n",
    "annuli = np.array([ 20., 100., 200., 300. ])\n",
    "edges_log = np.logspace( -1., np.log10( sidelength), 64 )\n",
    "edges = np.linspace( 0., sidelength, 64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = edges[:-1] + 0.5 * ( edges[1] - edges[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_log = 10.**( np.log10( edges_log[:-1] ) + 0.5 * ( np.log10( edges_log[1] ) - np.log10( edges_log[0] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_bin = round( n / (edges_log.size - 1 ) / 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup idealized projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips = {}\n",
    "all_length_scales = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main halo\n",
    "r_vir = 250.\n",
    "m_vir = 1e12\n",
    "\n",
    "# Filament\n",
    "filament_val = 3e7\n",
    "dx = -400.\n",
    "theta_b = 100.\n",
    "\n",
    "# Clumps\n",
    "dr = 0.1\n",
    "r_clumps = 10.**np.arange( -1, 2 + dr, dr )\n",
    "f_covs = np.arange( 0.1, 1.0, 0.1 )\n",
    "clump_val = 5e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control w no clumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = idealized.IdealizedProjection( sidelength )\n",
    "ip.add_nfw_nopatch(\n",
    "    center = (0., 0.),\n",
    "    r_vir = r_vir,\n",
    "    m_vir = m_vir,\n",
    "    n_annuli = 64,\n",
    ")\n",
    "edge_val = min( ip.struct_values )\n",
    "\n",
    "# # Satellite\n",
    "# # ip.add_sphere(\n",
    "# #     c = (-250., 50.),\n",
    "# #     r = r_sat,\n",
    "# #     value = value_sat,\n",
    "# #     n_annuli = 64,\n",
    "# # )\n",
    "\n",
    "# # Filament\n",
    "# ip.add_curve(\n",
    "#     v1 = (0., 0.),\n",
    "#     v2 = (dx, 60.),\n",
    "#     theta_a = 20.,\n",
    "#     theta_b = theta_b,\n",
    "#     value = filament_val,\n",
    "# )\n",
    "# length_scales = {}\n",
    "# width = 40.\n",
    "# n_concentric = 40\n",
    "# ip.add_concentric_structures(\n",
    "#     ip.structs[-1],\n",
    "#     value = filament_val,\n",
    "#     n_concentric = n_concentric,\n",
    "#     dr = width / n_concentric,\n",
    "#     dv = - ( filament_val - edge_val ) / n_concentric\n",
    "# )\n",
    "\n",
    "length_scales = {}\n",
    "# length_scales['long'] = np.sqrt( dx**2. + 60.**2. )\n",
    "length_scales['halo'] = r_vir\n",
    "length_scales['annuli'] = 100.\n",
    "# length_scales['satellite'] = r_sat\n",
    "\n",
    "ips['fcov0.0'] = { 'rclump0.0': ip }\n",
    "all_length_scales['fcov0.0'] = { 'rclump0.0': length_scales }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying clump radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm( total=f_covs.size*r_clumps.size, position=0, leave=True)\n",
    "\n",
    "for f_cov in f_covs:\n",
    "    fcov_key = 'fcov{:.3g}'.format( f_cov )\n",
    "    fcov_ips = {}\n",
    "    fcov_ls = {}\n",
    "    \n",
    "    for r_clump in r_clumps:\n",
    "        rclump_key = 'rclump{:.3g}'.format( r_clump )\n",
    "        \n",
    "        # Main halo\n",
    "        ip = idealized.IdealizedProjection(sidelength)\n",
    "        ip.add_nfw_nopatch(\n",
    "            center = (0., 0.),\n",
    "            r_vir = r_vir,\n",
    "            m_vir = m_vir,\n",
    "            n_annuli = 64,\n",
    "        )\n",
    "        edge_val = min( ip.struct_values )\n",
    "\n",
    "#         # Filament\n",
    "#         ip.add_curve(\n",
    "#             v1 = (0., 0.),\n",
    "#             v2 = (dx, 60.),\n",
    "#             theta_a = 20.,\n",
    "#             theta_b = theta_b,\n",
    "#             value = filament_val,\n",
    "#         )\n",
    "#         width = 40.\n",
    "#         n_concentric = 40\n",
    "#         ip.add_concentric_structures(\n",
    "#             ip.structs[-1],\n",
    "#             value = filament_val,\n",
    "#             n_concentric = n_concentric,\n",
    "#             dr = width / n_concentric,\n",
    "#             dv = - ( filament_val - edge_val ) / n_concentric\n",
    "#         )\n",
    "\n",
    "        # Clumps\n",
    "        ip.add_clumps_nopatch(\n",
    "            r_clump = r_clump,\n",
    "            c = (0., 0.),\n",
    "            r_area = r_vir,\n",
    "            fcov = f_cov,\n",
    "            value = clump_val,\n",
    "        )\n",
    "        length_scales = {}\n",
    "        # length_scales['long'] = np.sqrt( 300.**2. + 60.**2. )\n",
    "        length_scales['halo'] = r_vir\n",
    "        length_scales['clump'] = r_clump\n",
    "        length_scales['annuli'] = 100.\n",
    "        \n",
    "        # Generate projection\n",
    "        ip.generate_idealized_projection()\n",
    "        \n",
    "        pbar.update( 1 )\n",
    "\n",
    "        # structs, values = copy.copy( ip.structs ), copy.copy( ip.struct_values )\n",
    "        # for i, (struct, value) in enumerate( zip( *[ structs, values ] ) ):\n",
    "        #     width = 10.\n",
    "        #     n_concentric = 10\n",
    "        #     ip.add_concentric_structures(\n",
    "        #         ip.structs[-1],\n",
    "        #         value = filament_val,\n",
    "        #         n_concentric = n_concentric,\n",
    "        #         dr = width / n_concentric,\n",
    "        #         dv = - ( filament_val - 1. ) / n_concentric\n",
    "        #     )\n",
    "        \n",
    "        fcov_ips[rclump_key] = ip\n",
    "        fcov_ls[rclump_key] = length_scales\n",
    "    ips[fcov_key] = fcov_ips\n",
    "    all_length_scales[fcov_key] = fcov_ls\n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Paired Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_edges = np.array([ ip.ip_values.min(), ip.ip_values.max() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sampler = sample.PairSampler( ip.sidelength, edges_log, v_edges )\n",
    "dr_coords1, dr_coords2 = pair_sampler.generate_pair_sampling_coords(\n",
    "    n_per_bin = n_per_bin,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_coords = np.concatenate([ np.concatenate( dr_coords1 ), np.concatenate( dr_coords2 ) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pair-sampled, weighted TPCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm( total=f_covs.size*r_clumps.size + 1, position=0, leave=True)\n",
    "\n",
    "fcovs = {}\n",
    "tpcfs = {}\n",
    "for fcov_key, f_cov_ips in ips.items():\n",
    "    tpcfs_fcov = {}\n",
    "    fcovs_fcov = {}\n",
    "    \n",
    "    for rclump_key, ip in f_cov_ips.items():\n",
    "        \n",
    "        # Get data\n",
    "        ip.set_sightlines( pair_coords )\n",
    "        ws = ip.evaluate_sightlines()\n",
    "\n",
    "        tpcf, edges = stats.weighted_tpcf(\n",
    "            pair_coords,\n",
    "            ws,\n",
    "            edges_log,\n",
    "        )\n",
    "        \n",
    "        pbar.update( 1 )\n",
    "    \n",
    "        tpcfs_fcov[rclump_key] = tpcf\n",
    "        fcovs_fcov[rclump_key] = ( ws >= 0.999*clump_val ).sum() / float( ws.size )\n",
    "        \n",
    "    tpcfs[fcov_key] = tpcfs_fcov\n",
    "    fcovs[fcov_key] = fcovs_fcov\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate delta(TPCF=0.25,0.5,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = {}\n",
    "for intercept in [ 0.25, 0.5, 0.75 ]:\n",
    "    intercepts_part = {}\n",
    "    for i, (fcov_key, f_cov_tpcfs) in enumerate( tpcfs.items() ):\n",
    "\n",
    "        half_intercepts_fcov = {}\n",
    "\n",
    "        for j, (rclump_key, tpcf) in enumerate( f_cov_tpcfs.items() ):  \n",
    "\n",
    "            interp_fn = scipy.interpolate.interp1d( np.log10( xs_log ), tpcf )\n",
    "\n",
    "            def root_fn( delta ):\n",
    "\n",
    "                return interp_fn( delta ) - intercept\n",
    "\n",
    "            try:\n",
    "                sol = scipy.optimize.root_scalar( root_fn, method='brentq', bracket=[ np.log10( xs_log[0] ), np.log10( 5e2 ) ], )\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            half_intercepts_fcov[rclump_key] = sol.root\n",
    "\n",
    "        intercepts_part[fcov_key] = half_intercepts_fcov   \n",
    "    intercepts[intercept] = intercepts_part\n",
    "intercepts = verdict.Dict( intercepts )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = len( r_clumps )\n",
    "nrows = len( f_covs ) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_or_not( label, do_label ):\n",
    "    \n",
    "    if do_label:\n",
    "        return label\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = palettable.matplotlib.Viridis_4.mpl_colors[1:][::-1]\n",
    "arc_color = palettable.cartocolors.qualitative.Pastel_10.mpl_colors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['xtick.major.size'] = 10\n",
    "matplotlib.rcParams['xtick.major.width'] = 2\n",
    "matplotlib.rcParams['xtick.minor.size'] = 5\n",
    "matplotlib.rcParams['xtick.minor.width'] = 1.4\n",
    "matplotlib.rcParams['ytick.major.size'] = 10\n",
    "matplotlib.rcParams['ytick.major.width'] = 2\n",
    "matplotlib.rcParams['ytick.minor.size'] = 5\n",
    "matplotlib.rcParams['ytick.minor.width'] = 1.4\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=16) \n",
    "matplotlib.rc('ytick', labelsize=16) \n",
    "\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Axis TPCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12,8), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "for i, (fcov_key, f_cov_tpcfs) in enumerate( tpcfs.items() ):\n",
    "    \n",
    "    for j, (rclump_key, tpcf) in enumerate( f_cov_tpcfs.items() ):  \n",
    "    \n",
    "        # TPCFs\n",
    "        ax.plot(\n",
    "            xs_log,\n",
    "            tpcf,\n",
    "            linewidth = 6,\n",
    "            color = 'k',\n",
    "            label = i,\n",
    "            zorder = -1,\n",
    "        )\n",
    "        \n",
    "        ax.axvline(\n",
    "            10.**half_intercepts[fcov_key][rclump_key]\n",
    "        )\n",
    "        \n",
    "ax.axhline(\n",
    "    0.5,\n",
    ")\n",
    "    \n",
    "# Axis tweaks\n",
    "ax.set_xlim( 0.9, xs_log[-1] )\n",
    "ax.set_xscale( 'log' )\n",
    "ax.set_ylim( -0.5, 1. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot delta(TPCF=0.5) vs Rclump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12,12), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "for i, (fcov_key, f_cov_his) in enumerate( half_intercepts.items() ):\n",
    "    \n",
    "    # Reformat\n",
    "    r_clumps_plot = []\n",
    "    his_plot = []\n",
    "    for j, (rclump_key, f_cov_hi) in enumerate( f_cov_his.items() ):  \n",
    "        r_clumps_plot.append( float( rclump_key[6:] ) )\n",
    "        his_plot.append( 10.**f_cov_hi )\n",
    "        \n",
    "    ax.scatter(\n",
    "        r_clumps_plot,\n",
    "        his_plot,\n",
    "        s = 70,\n",
    "        color = palettable.matplotlib.Viridis_10.mpl_colormap( float( fcov_key[4:] ) ),\n",
    "    )\n",
    "    \n",
    "ax.plot(\n",
    "    [ 0.1, 1e2 ],\n",
    "    [ 0.1, 1e2 ],\n",
    "    color = 'k',\n",
    "    linestyle = '--',\n",
    "    linewidth = 3,\n",
    ")\n",
    "    \n",
    "ax.set_aspect( 'equal' )\n",
    "    \n",
    "ax.set_xscale( 'log' )\n",
    "ax.set_yscale( 'log' )\n",
    "\n",
    "ax.set_xlabel( r'$R({\\rm clump})$ (kpc)', fontsize=22 )\n",
    "ax.set_ylabel( r'$\\delta(\\Xi=0.5)$ (kpc)', fontsize=22 )\n",
    "\n",
    "fig.savefig('./characteristic_r.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
